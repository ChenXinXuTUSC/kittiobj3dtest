{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "import easydict\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lidar_info(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    point_num = int(size / 16)\n",
    "    assert point_num * 16 == size, \"invalid binary structure\"\n",
    "\n",
    "    lidar_pt_list = []\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        bin_data = None\n",
    "        while True:\n",
    "            bin_data = f.read(4)\n",
    "            if len(bin_data) < 4:\n",
    "                break\n",
    "            lidar_pt_list.append(struct.unpack('f', bin_data))\n",
    "    return np.array(lidar_pt_list).reshape((-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = \"004369\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35.11199951  4.33099985  1.40499997  0.        ]\n",
      " [78.68599701  9.98900032  2.89100003  0.        ]\n",
      " [78.71299744 10.24400043  2.89299989  0.        ]\n",
      " ...\n",
      " [ 3.79999995 -1.40400004 -1.773       0.        ]\n",
      " [16.11199951 -4.49900007 -7.68400002  0.23      ]\n",
      " [16.2329998  -4.47800016 -7.73600006  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "lidar_pt = read_lidar_info(f\"data/training/velodyne/{sample_index}.bin\")\n",
    "print(lidar_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(lidar_pt[:, :3])\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.ones((len(lidar_pt), 3)) * lidar_pt[:, 3].reshape((-1, 1)))\n",
    "pcd_ds = pcd.voxel_down_sample(0.05)\n",
    "o3d.io.write_point_cloud(\"data/output/output.ply\", pcd_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![snapshot](data/images/Snipaste_2024-11-28_20-27-59.png)\n",
    "![snapshot](data/images/Snipaste_2024-11-29_10-28-22.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label file field explanation\n",
    "\n",
    "- `<object_type>:` The type of the annotated object. This can be one of the following: 'Car', 'Van', 'Truck', 'Pedestrian', - 'Person_sitting', 'Cyclist', 'Tram', 'Misc', or 'DontCare'. 'DontCare' is used for objects that are present but ignored for evaluation.\n",
    "- `<truncation>`: The fraction of the object that is visible. It is a float value in the range [0.0, 1.0]. A value of 0.0 means the - object is fully visible, and 1.0 means the object is completely outside the image frame.\n",
    "- `<occlusion>`: The level of occlusion of the object. It is an integer value indicating the degree of occlusion, where 0 means fully - visible, and higher values indicate increasing levels of occlusion.\n",
    "- `<alpha>`: The observation angle of the object in radians, relative to the camera. It is the angle between the object's heading - direction and the positive x-axis of the camera.\n",
    "- `<left>, <top>, <right>, <bottom>`: The 2D bounding box coordinates of the object in the image. They represent the pixel locations of - the top-left and bottom-right corners of the bounding box.\n",
    "- `<height>, <width>, <length>`: The 3D dimensions of the object (height, width, and length) in meters.\n",
    "- `<x>, <y>, <z>`: The 3D location of the object's centroid in the camera coordinate system (in meters).\n",
    "- `<rotation_y>`: The rotation of the object around the y-axis in camera coordinates, in radians.\n",
    "\n",
    "see also: https://medium.com/@abdulhaq.ah/explain-label-file-of-kitti-dataset-738528de36f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 0.0, 'alpha': -1.65, 'left': 634.89, 'top': 184.77, 'right': 675.04, 'bottom': 213.79, 'height': 1.32, 'width': 1.63, 'length': 4.1, 'x': 2.15, 'y': 1.93, 'z': 35.89, 'rotation_y': -1.6}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 2.0, 'alpha': 0.21, 'left': 394.31, 'top': 178.6, 'right': 507.49, 'bottom': 219.61, 'height': 1.58, 'width': 1.56, 'length': 4.25, 'x': -6.44, 'y': 1.84, 'z': 29.32, 'rotation_y': -0.0}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 1.0, 'alpha': -0.3, 'left': 733.33, 'top': 182.14, 'right': 880.89, 'bottom': 236.7, 'height': 1.5, 'width': 1.62, 'length': 3.88, 'x': 5.71, 'y': 1.8, 'z': 21.31, 'rotation_y': -0.04}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 2.0, 'alpha': -2.83, 'left': 202.13, 'top': 171.25, 'right': 419.02, 'bottom': 258.03, 'height': 1.77, 'width': 1.68, 'length': 4.12, 'x': -6.54, 'y': 1.76, 'z': 16.01, 'rotation_y': 3.07}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 2.0, 'alpha': 0.52, 'left': 143.09, 'top': 182.82, 'right': 408.54, 'bottom': 270.33, 'height': 1.51, 'width': 1.59, 'length': 4.28, 'x': -6.19, 'y': 1.72, 'z': 13.49, 'rotation_y': 0.1}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 2.0, 'alpha': 0.53, 'left': 76.7, 'top': 188.66, 'right': 378.34, 'bottom': 296.25, 'height': 1.5, 'width': 1.49, 'length': 3.86, 'x': -5.77, 'y': 1.77, 'z': 11.03, 'rotation_y': 0.06}\n",
      "{'object_type': 'Car', 'truncation': 0.23, 'occlusion': 3.0, 'alpha': 0.66, 'left': 0.0, 'top': 188.1, 'right': 280.95, 'bottom': 322.89, 'height': 1.48, 'width': 1.59, 'length': 3.45, 'x': -6.21, 'y': 1.7, 'z': 8.94, 'rotation_y': 0.07}\n",
      "{'object_type': 'Car', 'truncation': 0.71, 'occlusion': 0.0, 'alpha': -2.46, 'left': 0.0, 'top': 192.02, 'right': 220.72, 'bottom': 374.0, 'height': 1.52, 'width': 1.64, 'length': 4.07, 'x': -5.98, 'y': 1.72, 'z': 6.37, 'rotation_y': 3.09}\n",
      "{'object_type': 'Car', 'truncation': 0.0, 'occlusion': 2.0, 'alpha': -0.56, 'left': 878.59, 'top': 183.33, 'right': 1151.02, 'bottom': 291.08, 'height': 1.55, 'width': 1.58, 'length': 3.51, 'x': 6.34, 'y': 1.74, 'z': 11.59, 'rotation_y': -0.07}\n",
      "{'object_type': 'Car', 'truncation': 0.17, 'occlusion': 0.0, 'alpha': -0.68, 'left': 947.14, 'top': 191.7, 'right': 1241.0, 'bottom': 318.05, 'height': 1.4, 'width': 1.59, 'length': 3.49, 'x': 6.42, 'y': 1.67, 'z': 9.3, 'rotation_y': -0.09}\n",
      "{'object_type': 'DontCare', 'truncation': -1.0, 'occlusion': -1.0, 'alpha': -10.0, 'left': 483.2, 'top': 176.33, 'right': 580.2, 'bottom': 201.53, 'height': -1.0, 'width': -1.0, 'length': -1.0, 'x': -1000.0, 'y': -1000.0, 'z': -1000.0, 'rotation_y': -10.0}\n",
      "{'object_type': 'DontCare', 'truncation': -1.0, 'occlusion': -1.0, 'alpha': -10.0, 'left': 586.05, 'top': 175.36, 'right': 600.57, 'bottom': 188.92, 'height': -1.0, 'width': -1.0, 'length': -1.0, 'x': -1000.0, 'y': -1000.0, 'z': -1000.0, 'rotation_y': -10.0}\n",
      "{'object_type': 'DontCare', 'truncation': -1.0, 'occlusion': -1.0, 'alpha': -10.0, 'left': 612.25, 'top': 180.21, 'right': 648.12, 'bottom': 194.74, 'height': -1.0, 'width': -1.0, 'length': -1.0, 'x': -1000.0, 'y': -1000.0, 'z': -1000.0, 'rotation_y': -10.0}\n",
      "P0 [721.5377, 0.0, 609.5593, 0.0, 0.0, 721.5377, 172.854, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "P1 [721.5377, 0.0, 609.5593, -387.5744, 0.0, 721.5377, 172.854, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "P2 [721.5377, 0.0, 609.5593, 44.85728, 0.0, 721.5377, 172.854, 0.2163791, 0.0, 0.0, 1.0, 0.002745884]\n",
      "P3 [721.5377, 0.0, 609.5593, -339.5242, 0.0, 721.5377, 172.854, 2.199936, 0.0, 0.0, 1.0, 0.002729905]\n",
      "R0_rect [0.9999239, 0.00983776, -0.007445048, -0.009869795, 0.9999421, -0.004278459, 0.007402527, 0.004351614, 0.9999631]\n",
      "Tr_velo_to_cam [0.007533745, -0.9999714, -0.000616602, -0.004069766, 0.01480249, 0.0007280733, -0.9998902, -0.07631618, 0.9998621, 0.00752379, 0.01480755, -0.2717806]\n",
      "Tr_imu_to_velo [0.9999976, 0.0007553071, -0.002035826, -0.8086759, -0.0007854027, 0.9998898, -0.01482298, 0.3195559, 0.002024406, 0.01482454, 0.9998881, -0.7997231]\n"
     ]
    }
   ],
   "source": [
    "# label the thing with colors\n",
    "def is_float(item):\n",
    "    try:\n",
    "        item = float(item)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "label_field_name_list = [\n",
    "    \"object_type\",\n",
    "    \"truncation\",\n",
    "    \"occlusion\",\n",
    "    \"alpha\",\n",
    "    \"left\", \"top\", \"right\", \"bottom\",\n",
    "    \"height\", \"width\", \"length\",\n",
    "    \"x\", \"y\", \"z\",\n",
    "    \"rotation_y\"\n",
    "]\n",
    "label_list = []\n",
    "with open(f\"data/training/label_2/{sample_index}.txt\", 'r') as f:\n",
    "    label_list = [tuple([float(item) if is_float(item) else item for item in line.strip().split()]) for line in f.readlines()]\n",
    "# transform each label to dictionary item\n",
    "label_list = [\n",
    "    easydict.EasyDict({field:value for (field, value) in zip(label_field_name_list, item)}) for item in label_list\n",
    "]\n",
    "\n",
    "calib_field_name_list = [\n",
    "    \"P0\", \"P1\", \"P2\", \"P3\",\n",
    "    \"R0_rect\", \"Tr_velo_to_cam\", \"Tr_imu_to_velo\"\n",
    "]\n",
    "calib_info = []\n",
    "with open(f\"data/training/calib/{sample_index}.txt\", 'r') as f:\n",
    "    calib_list = [line.strip().split() for line in f.readlines() if len(line.strip()) > 0]\n",
    "calib_info = easydict.EasyDict(\n",
    "    {seq[0][:-1]:[float(x) for x in seq[1:]] for seq in calib_list}\n",
    ")\n",
    "\n",
    "print(*label_list, sep='\\n')\n",
    "for key, val in calib_info.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_mat(angle: float, axis, radian: bool=True):\n",
    "    \"\"\"\n",
    "    generate the 3x3 rotation matrix with the specified axis and angle\n",
    "\n",
    "    - param angle: rotation angle, in radian\n",
    "    - param axis: rotation axis, [1,3] or [3]\n",
    "    - return: rotation matrix R [3,3]\n",
    "    \"\"\"\n",
    "    # angle to radian\n",
    "    angle_rad = angle\n",
    "    if not radian:\n",
    "        angle_rad = np.radians(angle)\n",
    "\n",
    "    # normalize rotation axis\n",
    "    if type(axis) is not np.ndarray:\n",
    "        axis = np.array(axis)\n",
    "    axis = axis / np.linalg.norm(axis)\n",
    "\n",
    "    # compute each component\n",
    "    x, y, z = axis\n",
    "    c = np.cos(angle_rad)\n",
    "    s = np.sin(angle_rad)\n",
    "    C = 1 - c\n",
    "\n",
    "    # build the rotation matrix\n",
    "    rotation_matrix = np.array([\n",
    "        [x*x*C + c,   x*y*C - z*s, x*z*C + y*s],\n",
    "        [y*x*C + z*s, y*y*C + c,   y*z*C - x*s],\n",
    "        [z*x*C - y*s, z*y*C + x*s, z*z*C + c  ]\n",
    "    ])\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "\n",
    "def T_mat(values: list):\n",
    "    return np.array(values).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add label colors\n",
    "\n",
    "Note that `<x,y,z>` coordinates in the KITTI object detection dataset are placed under the camera coordinate, if it's to be used with lidar point cloud data, you should do the coordinate transformation first\n",
    "\n",
    "![kitti_coor](data/images/kitti_coord.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car 12\n",
      "Car 103\n",
      "Car 311\n",
      "Car 6\n",
      "Car 165\n",
      "Car 596\n",
      "Car 272\n",
      "Car 20\n",
      "Car 494\n",
      "Car 1124\n"
     ]
    }
   ],
   "source": [
    "points = lidar_pt[:, :3]\n",
    "colors = np.zeros(points.shape)\n",
    "\n",
    "anchor_points = []\n",
    "anchor_colors = []\n",
    "for label in label_list:\n",
    "    if (label.object_type == \"DontCare\"):\n",
    "        continue\n",
    "\n",
    "    radn = label.rotation_y\n",
    "    axis = [0, 1, 0]\n",
    "    R = R_mat(radn, axis)\n",
    "    T = T_mat([label.x, label.y, label.z])\n",
    "    \n",
    "    # transform from camera coordinate to velodyn coordinate\n",
    "    vly2cam = np.array(calib_info.Tr_velo_to_cam).reshape((3, 4))\n",
    "    T = vly2cam[:3,:3].T @ (T - vly2cam[:, 3].reshape((-1, 1)))\n",
    "    \n",
    "    # visualize center point\n",
    "    anchor_points.append(T.T)\n",
    "    anchor_colors.append([0.0, 1.0, 0.0])\n",
    "\n",
    "    # visualize bounding box corner\n",
    "    lb_coord = np.array([-label.width/2, -label.length/2, 0.0])\n",
    "    rt_coord = np.array([+label.width/2, +label.length/2, +label.height])\n",
    "    anchor_points.append(lb_coord @ R.T + T.T)\n",
    "    anchor_points.append(rt_coord @ R.T + T.T)\n",
    "    anchor_colors.append([1.0, 0.0, 0.0])\n",
    "    anchor_colors.append([1.0, 0.0, 0.0])\n",
    "\n",
    "    # visualize detection area\n",
    "    points_r = (points - T.T) @ R\n",
    "    mask = np.all((points_r >= lb_coord) & (points_r <= rt_coord), axis=1)\n",
    "    print(label.object_type, \"includes point num:\", mask.astype(np.int32).sum())\n",
    "\n",
    "    colors[mask] = np.array([0.0, 0.0, 1.0])\n",
    "    \n",
    "\n",
    "points = np.vstack([points, np.vstack(anchor_points)]) # add other points to main part\n",
    "colors = np.vstack([colors, np.vstack(anchor_colors)]) # add other colors to main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "pcd_ds = pcd.voxel_down_sample(0.05)\n",
    "o3d.io.write_point_cloud(\"data/output/gdth.ply\", pcd_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bounding box segmentation result\n",
    "![bbox_visualization](data/images/bbox_seg.png)\n",
    "\n",
    "Green dots represent the center of the bottom of the bounding box, red dots represent left bottom and right top corners of the bounding box, blue dots represent the `object_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1) (3, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,1,1]]).reshape((-1, 1))\n",
    "b = np.array([[1,1,1]]).reshape((-1, 1))\n",
    "\n",
    "print(a.shape, b.shape)\n",
    "c = a - b\n",
    "\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
